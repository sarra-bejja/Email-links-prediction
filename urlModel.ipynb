{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i strated a session and tested it\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PhishTounsi_Urls\").config(\"spark.task.maxFailures\", \"8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_df = spark.read.csv(\"balanced_urls.csv\", header=True, inferSchema=True)\n",
    "\n",
    "urls_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "urls_merged_df = urls_merged_df.withColumn(\"label\", \n",
    "                                           when((urls_merged_df[\"is_spam\"] == \"true\"), 1)\n",
    "                                           .otherwise(0))\n",
    "\n",
    "urls_merged_df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Remove duplicates\n",
    "urls_merged_df = urls_merged_df.dropDuplicates([\"urls\"])\n",
    "\n",
    "\n",
    "# Filter out invalid URLs\n",
    "urls_merged_df= urls_merged_df.filter(col(\"urls\").rlike(r\"^https?://\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length, regexp_replace, split\n",
    "\n",
    "# Feature: URL length\n",
    "urls_merged_df = urls_merged_df.withColumn(\"url_length\", length(col(\"urls\")))\n",
    "\n",
    "# Feature: Special character count\n",
    "urls_merged_df= urls_merged_df.withColumn(\"special_char_count\", length(regexp_replace(col(\"urls\"), \"[^@#?=%&-]\", \"\")))\n",
    "\n",
    "# Feature: Presence of IP address\n",
    "urls_merged_df= urls_merged_df.withColumn(\"contains_ip\", when(col(\"urls\").rlike(r\"[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+\"), 1).otherwise(0))\n",
    "urls_merged_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "\n",
    "# Convert URLs to lowercase\n",
    "urls_merged_df= urls_merged_df.withColumn(\"urls\", lower(col(\"urls\")))\n",
    "\n",
    "# Filter out short URLs (e.g., less than 10 characters)\n",
    "urls_merged_df =urls_merged_df.filter(length(col(\"urls\")) > 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length, when, split, col, size\n",
    "\n",
    "# Feature: Domain length\n",
    "urls_merged_df = urls_merged_df.withColumn(\n",
    "    \"domain_length\", \n",
    "    length(split(col(\"urls\"), \"/\")[2])  # Get the domain part of the URL\n",
    ")\n",
    "\n",
    "# Feature: Suspicious TLDs\n",
    "urls_merged_df= urls_merged_df.withColumn(\n",
    "    \"suspicious_tld\", \n",
    "    when(col(\"urls\").rlike(r\"\\.(xyz|info|tk|top|icu)$\"), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Feature: HTTPS usage\n",
    "urls_merged_df =urls_merged_df.withColumn(\n",
    "    \"uses_https\", \n",
    "    when(col(\"urls\").startswith(\"https\"), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Feature: Subdomain count\n",
    "urls_merged_df= urls_merged_df.withColumn(\n",
    "    \"subdomain_count\", \n",
    "    size(split(col(\"urls\"), \"\\\\.\")) - 2  # Subdomains are the parts before the domain, adjust accordingly\n",
    ")\n",
    "\n",
    "# Feature: Presence of phishing keywords\n",
    "urls_merged_df =urls_merged_df.withColumn(\n",
    "    \"phishing_keywords\", \n",
    "    when(col(\"urls\").rlike(r\"(login|verify|secure|bank|update)\"), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Feature: URL encoding\n",
    "urls_merged_df = urls_merged_df.withColumn(\n",
    "    \"url_encoded\", \n",
    "    when(col(\"urls\").rlike(r\"%[0-9A-Fa-f]{2}\"), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Show the resulting DataFrame with the new features\n",
    "urls_merged_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Define the list of feature columns to be included in the model\n",
    "feature_columns = [\n",
    "    \"url_length\", \"special_char_count\", \"contains_ip\", \"domain_length\",\n",
    "    \"suspicious_tld\", \"uses_https\", \"subdomain_count\", \"phishing_keywords\", \"url_encoded\"\n",
    "]\n",
    "\n",
    "# Assemble features into a single vector column\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "urls_merged_df = assembler.transform(urls_merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "train_ratio = 0.8\n",
    "urls_train_df, urls_test_df = urls_merged_df.randomSplit([train_ratio, 1 - train_ratio], seed=42)\n",
    "\n",
    "# Check the count of each label (0 and 1) in the training set\n",
    "train_counts = urls_train_df.groupBy(\"label\").count()\n",
    "\n",
    "# Check the count of each label (0 and 1) in the testing set\n",
    "test_counts = urls_test_df.groupBy(\"label\").count()\n",
    "\n",
    "# Show the counts for both training and testing sets\n",
    "train_counts.show()\n",
    "test_counts.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
